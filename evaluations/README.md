# evaluations â€” Function Calling ëª¨ë¸ í‰ê°€ íŒ¨í‚¤ì§€

LLMì˜ Function Calling(ë„êµ¬ í˜¸ì¶œ) ì„±ëŠ¥ì„ ì •ëŸ‰ì ìœ¼ë¡œ í‰ê°€í•˜ê¸° ìœ„í•œ íŒ¨í‚¤ì§€ì…ë‹ˆë‹¤.  
**BFCL 3ëŒ€ ë©”íŠ¸ë¦­ + Unitxt 6ì¢… ë¶„í•´ ë©”íŠ¸ë¦­ + HammerBench ë©€í‹°í„´ í‰ê°€**ë¥¼ í•œ ë²ˆì— ê³„ì‚°í•©ë‹ˆë‹¤.

---

## ğŸ“ íŒŒì¼ êµ¬ì¡°

```
evaluations/
â”œâ”€â”€ __init__.py              # íŒ¨í‚¤ì§€ ì´ˆê¸°í™”
â”œâ”€â”€ metrics.py               # BFCL + Unitxt í†µí•© ë©”íŠ¸ë¦­ (í•µì‹¬)
â”œâ”€â”€ multi_turn_metrics.py    # HammerBench ìŠ¤íƒ€ì¼ ë©€í‹°í„´ í‰ê°€
â”œâ”€â”€ preprocessing.py         # ë°ì´í„° ì „ì²˜ë¦¬ ìœ í‹¸ë¦¬í‹°
â”œâ”€â”€ runner.py                # vLLM ê¸°ë°˜ ì „ì²´ í‰ê°€ íŒŒì´í”„ë¼ì¸ CLI
â””â”€â”€ README.md                # ì´ ë¬¸ì„œ
```

---

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. ì‹±ê¸€í„´ í‰ê°€ (GPU ë¶ˆí•„ìš”)

ëª¨ë¸ ì¶œë ¥ì´ ìˆë‹¤ë©´ `evaluate_function_calls`ë§Œ í˜¸ì¶œí•˜ë©´ ë©ë‹ˆë‹¤.

```python
from evaluations.metrics import evaluate_function_calls

labels = [
    '<tool_call>\n{"name": "view_user_profile", "arguments": {"user_id": "U002"}}\n</tool_call>',
    '<tool_call>\n{"name": "search_product", "arguments": {"keyword": "ë…¸íŠ¸ë¶"}}\n</tool_call>',
    'ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?',
]

predictions = [
    '<tool_call>\n{"name": "view_user_profile", "arguments": {"user_id": "U002"}}\n</tool_call>',
    '<tool_call>\n{"name": "search_product", "arguments": {"keyword": "ë§ˆìš°ìŠ¤"}}\n</tool_call>',
    'ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?',
]

results = evaluate_function_calls(labels, predictions)
print(results.summary())
```

ì¶œë ¥:
```
=== Function Calling í‰ê°€ ê²°ê³¼ ===

[BFCL ë©”íŠ¸ë¦­]
  exact_match (ASTAcc)     : 50.00%
  relevance_detection (F1) : 100.00%

[Unitxt ë¶„í•´ ë©”íŠ¸ë¦­]
  tool_selection           : 100.00%
  param_name_recall        : 100.00%
  param_name_precision     : 100.00%
  params_value_accuracy    : 50.00%
  schema_valid_rate        : N/A (ìŠ¤í‚¤ë§ˆ ë¯¸ì œê³µ)
```

### 2. ë©€í‹°í„´ í‰ê°€ (HammerBench ìŠ¤íƒ€ì¼)

ëŒ€í™” ë‹¨ìœ„ë¡œ í„´ë³„ ì •í™•ë„ì™€ ì˜¤ë¥˜ ì—°ì‡„ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.

```python
from evaluations.multi_turn_metrics import evaluate_multi_turn

# ëŒ€í™”ë³„ í„´ ë¦¬ìŠ¤íŠ¸ì˜ ë¦¬ìŠ¤íŠ¸
conv_labels = [
    [  # ëŒ€í™” 1: ê²€ìƒ‰ â†’ ì£¼ë¬¸
        '<tool_call>\n{"name": "search", "arguments": {"q": "ì¹˜í‚¨"}}\n</tool_call>',
        '<tool_call>\n{"name": "order", "arguments": {"id": "1"}}\n</tool_call>',
    ],
]

conv_preds = [
    [  # ëŒ€í™” 1: ê²€ìƒ‰ ë§ìŒ, ì£¼ë¬¸ í‹€ë¦¼
        '<tool_call>\n{"name": "search", "arguments": {"q": "ì¹˜í‚¨"}}\n</tool_call>',
        '<tool_call>\n{"name": "wrong_fn", "arguments": {"id": "1"}}\n</tool_call>',
    ],
]

results = evaluate_multi_turn(conv_labels, conv_preds)
print(results.summary())
```

ì¶œë ¥:
```
=== ë©€í‹°í„´ í‰ê°€ ê²°ê³¼ (HammerBench) ===

[ë©€í‹°í„´ ë©”íŠ¸ë¦­]
  turn_level_accuracy      : 50.00%
  conversation_success_rate: 0.00%
  first_failure_turn_avg   : 1.0
  error_cascade_rate       : 0.00%
```

### 3. ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (GPU í•„ìš”)

ë°ì´í„°ì…‹ë§Œ ì§€ì •í•˜ë©´ **ìŠ¤í‚¤ë§ˆ ìë™ ì¶”ì¶œ â†’ vLLM ì¶”ë¡  â†’ ë©”íŠ¸ë¦­ ê³„ì‚° â†’ ê²°ê³¼ ì¶œë ¥**ì„ í•œ ë²ˆì— ìˆ˜í–‰í•©ë‹ˆë‹¤.

```bash
# ê¸°ë³¸ í‰ê°€ (BFCL + Unitxt + ìŠ¤í‚¤ë§ˆ ê²€ì¦)
python -m evaluations.runner \
    --model Qwen/Qwen2.5-7B-Instruct \
    --dataset jjun123/delivery-app-function-calling-datasets-korean

# ë©€í‹°í„´(HammerBench) í‰ê°€ë„ í¬í•¨
python -m evaluations.runner \
    --model Qwen/Qwen2.5-7B-Instruct \
    --dataset jjun123/delivery-app-function-calling-datasets-korean \
    --multi-turn
```

ë°ì´í„°ì…‹ì— `tools` í•„ë“œê°€ ìˆìœ¼ë©´ ìë™ìœ¼ë¡œ ìŠ¤í‚¤ë§ˆë¥¼ ì¶”ì¶œí•˜ì—¬ `schema_valid_rate`ë„ í•¨ê»˜ ì¸¡ì •í•©ë‹ˆë‹¤.

#### ì¡°ê±´ë³„ ì‹¤í–‰ ì˜ˆì‹œ

```bash
# 1) ë² ì´ìŠ¤ ëª¨ë¸ í‰ê°€
python -m evaluations.runner \
    --model Qwen/Qwen2.5-7B-Instruct \
    --dataset jjun123/delivery-app-function-calling-datasets-korean

# 2) ë©€í‹°í„´(HammerBench) í‰ê°€ í¬í•¨
python -m evaluations.runner \
    --model Qwen/Qwen2.5-7B-Instruct \
    --dataset jjun123/delivery-app-function-calling-datasets-korean \
    --multi-turn

# 3) í…ŒìŠ¤íŠ¸ ë¹„ìœ¨ ë³€ê²½ (50%ë¥¼ í…ŒìŠ¤íŠ¸ë¡œ)
python -m evaluations.runner \
    --model Qwen/Qwen2.5-7B-Instruct \
    --dataset jjun123/delivery-app-function-calling-datasets-korean \
    --test-ratio 0.5

# 4) ê²°ê³¼ë¥¼ íŠ¹ì • ê²½ë¡œì— ì €ì¥
python -m evaluations.runner \
    --model Qwen/Qwen2.5-7B-Instruct \
    --dataset jjun123/delivery-app-function-calling-datasets-korean \
    --output results/base_model_eval.csv

```

> âš ï¸ **`runner.py`ëŠ” vLLM + GPU í™˜ê²½ì—ì„œë§Œ ì‹¤í–‰ë©ë‹ˆë‹¤.** ë©”íŠ¸ë¦­ ê³„ì‚°ë§Œ í•„ìš”í•˜ë©´ `metrics.py`ë¥¼ ì§ì ‘ importí•˜ì„¸ìš”.

---

## ğŸ“Š ë©”íŠ¸ë¦­ ì²´ê³„ ì„¤ëª…

### ë©”íŠ¸ë¦­ì´ 3ì¢…ë¥˜ì¸ ì´ìœ 

| í”„ë ˆì„ì›Œí¬      | ì—­í•                                      | ë¹„ìœ          |
| --------------- | ---------------------------------------- | ------------ |
| **BFCL**        | "ì „ì²´ì ìœ¼ë¡œ ëª‡ ì ì¸ì§€" í•œëˆˆì— íŒŒì•…       | ì‹œí—˜ ì´ì     |
| **Unitxt**      | "ì™œ í‹€ë ¸ëŠ”ì§€" ì›ì¸ ë¶„í•´                  | ì˜¤ë‹µ ë¶„ì„í‘œ  |
| **HammerBench** | "ë©€í‹°í„´ì—ì„œ ì–´ë””ì„œ ë§ê°€ì§€ëŠ”ì§€" í„´ë³„ ì§„ë‹¨ | ëŒ€í™” CT ê²€ì‚¬ |

---

### BFCL 2ëŒ€ í•µì‹¬ ë©”íŠ¸ë¦­

| ë©”íŠ¸ë¦­                                  | ë³´ëŠ” ê²ƒ                                   | ì‰½ê²Œ ë§í•˜ë©´                   |
| --------------------------------------- | ----------------------------------------- | ----------------------------- |
| **exact_match** (â‰ˆ ASTAcc)              | í•¨ìˆ˜ëª… + ì¸ì ì´ë¦„/ê°’ì´ ì •ë‹µê³¼ ì™„ì „ ì¼ì¹˜? | "ì •ë‹µ JSONì´ë‘ ë˜‘ê°™ì´ ë±‰ì—ˆë‚˜" |
| **relevance_detection_f1** (â‰ˆ IrrelAcc) | í˜¸ì¶œí•˜ë©´ ì•ˆ ë˜ëŠ” ìƒí™©ì—ì„œ ê±°ë¶€í–ˆë‚˜?       | "íˆ´ ë‚¨ë°œ ì•ˆ í•˜ë‚˜"             |

---

### Unitxt 5ì¢… ë¶„í•´ ë©”íŠ¸ë¦­

| ë©”íŠ¸ë¦­                    | ì§ˆë¬¸                                   |
| ------------------------- | -------------------------------------- |
| **tool_selection**        | í•¨ìˆ˜ ì„ íƒì´ ë§ì•˜ë‚˜?                    |
| **param_name_recall**     | í•„ìˆ˜ ì¸ìë¥¼ ë¹ ì§ì—†ì´ ë„£ì—ˆë‚˜?           |
| **param_name_precision**  | ì“¸ë°ì—†ëŠ” ì¸ìë¥¼ ë„£ì§€ ì•Šì•˜ë‚˜?           |
| **params_value_accuracy** | ê°’ì´ ë§ë‚˜?                             |
| **schema_valid_rate**     | íƒ€ì…ì´ ìŠ¤í‚¤ë§ˆì— ë§ë‚˜? (ìŠ¤í‚¤ë§ˆ ì œê³µ ì‹œ) |

**ì›ì¸ ì§„ë‹¨ í™œìš©:**

| ì¦ìƒ                             | Unitxt ì§„ë‹¨             | ì²˜ë°©                               |
| -------------------------------- | ----------------------- | ---------------------------------- |
| Tool Selection â†‘ / Exact Match â†“ | íŒŒë¼ë¯¸í„° ìª½ ë¬¸ì œ        | íŒŒë¼ë¯¸í„° ë‹¤ì–‘ì„± ê°•í™”               |
| Param Name Recall â†“              | í•„ìˆ˜ ì¸ìë¥¼ ìì£¼ ë¹ ëœ¨ë¦¼ | required íŒŒë¼ë¯¸í„° í•™ìŠµ ë°ì´í„° ë³´ê°• |
| Param Name Precision â†“           | ë¶ˆí•„ìš”í•œ ì¸ì ì¶”ê°€      | ë¶ˆí•„ìš” íŒŒë¼ë¯¸í„° ì—†ëŠ” ì˜ˆì‹œ ë³´ê°•     |
| Value Precision â†“                | ê°’ ì¶”ì¶œ ì˜¤ë¥˜            | ë§¥ë½â†’ê°’ ì¶”ì¶œ íŒ¨í„´ í•™ìŠµ ë°ì´í„° ì¶”ê°€ |

---

### HammerBench 4ì¢… ë©€í‹°í„´ ë©”íŠ¸ë¦­

| ë©”íŠ¸ë¦­                        | ë³´ëŠ” ê²ƒ                             |
| ----------------------------- | ----------------------------------- |
| **turn_level_accuracy**       | ê°œë³„ í„´ ì •í™•ë„ í‰ê·                  |
| **conversation_success_rate** | ëŒ€í™” ì „ì²´ê°€ ëª¨ë“  í„´ ì •ë‹µì¸ ë¹„ìœ¨     |
| **first_failure_turn_avg**    | ì²« ì‹¤íŒ¨ê°€ ë°œìƒí•˜ëŠ” í„´ì˜ í‰ê·  ìœ„ì¹˜   |
| **error_cascade_rate**        | í•œ í„´ í‹€ë¦° í›„ ë‹¤ìŒ í„´ë„ í‹€ë¦¬ëŠ” ë¹„ìœ¨ |

> **error_cascade_rate**ê°€ ë†’ìœ¼ë©´ "ìê¸° ì¡°ê±´í™”(self-conditioning)" ë¬¸ì œì…ë‹ˆë‹¤.  
> ì´ˆê¸° í„´ì˜ ì˜¤ë¥˜ê°€ í›„ì† í„´ì— ì—°ì‡„ì ìœ¼ë¡œ ì „íŒŒë˜ê³  ìˆë‹¤ëŠ” ëœ»ì…ë‹ˆë‹¤.

---

## ğŸ” ì¢…í•© ì˜ˆì‹œ: ì—ëŸ¬ ì¼€ì´ìŠ¤ ë¶„ì„

| #   | ì •ë‹µ                                                    | ì˜ˆì¸¡                                    | ì°¨ì´ì               |
| --- | ------------------------------------------------------- | --------------------------------------- | ------------------- |
| 1   | `view_user_profile(user_id="U002")`                     | `view_profile(user_id="U002")`          | í•¨ìˆ˜ëª… í‹€ë¦¼         |
| 2   | `search_product(keyword="ë…¸íŠ¸ë¶", category="ì „ìê¸°ê¸°")` | `search_product(keyword="ë…¸íŠ¸ë¶")`      | category ëˆ„ë½       |
| 3   | `check_stock(product_id="P001")`                        | `"ì¬ê³  í™•ì¸ì€ ì œí’ˆ ë²ˆí˜¸ê°€ í•„ìš”í•©ë‹ˆë‹¤."` | tool_call ìì²´ ì‹¤íŒ¨ |

**BFCL ê²°ê³¼:**
- exact_match: **0.00%** (ì™„ì „ ì¼ì¹˜ ì—†ìŒ)

**Unitxt ë¶„í•´ ê²°ê³¼:**
- tool_selection: **33.33%** (3ê°œ ì¤‘ search_productë§Œ ë§ìŒ)
- param_name_recall: **50.00%** (ì •ë‹µ íŒŒë¼ë¯¸í„° 4ê°œ ì¤‘ 2ê°œë§Œ ì˜ˆì¸¡ì— í¬í•¨)
- param_name_precision: **100.00%** (ì˜ˆì¸¡í•œ íŒŒë¼ë¯¸í„° 2ê°œ ëª¨ë‘ ì •ë‹µì— ì¡´ì¬)
- params_value_accuracy: **66.67%** (ê³µí†µ íŒŒë¼ë¯¸í„° ê°’ 3ê°œ ì¤‘ 2ê°œ ì¼ì¹˜)

â†’ **ì§„ë‹¨**: í•¨ìˆ˜ ì„ íƒì´ ì£¼ìš” ë¬¸ì œ. Recallì€ ë‚®ì§€ë§Œ Precisionì€ ë†’ìŒ â†’ í•„ìˆ˜ ì¸ì ëˆ„ë½ì´ ì£¼ ì›ì¸.

---

## ğŸ§© í•¨ìˆ˜ ì‚¬ìš©ë²•

### `evaluate_function_calls(labels, predictions, tool_schemas=None) â†’ EvalResults`

| íŒŒë¼ë¯¸í„°       | íƒ€ì…                      | ì„¤ëª…                          |
| -------------- | ------------------------- | ----------------------------- |
| `labels`       | `list[str]`               | ì •ë‹µ ë ˆì´ë¸” ë¦¬ìŠ¤íŠ¸            |
| `predictions`  | `list[str]`               | ëª¨ë¸ ì˜ˆì¸¡ ë¦¬ìŠ¤íŠ¸              |
| `tool_schemas` | `dict[str, dict] \| None` | í•¨ìˆ˜ë³„ íŒŒë¼ë¯¸í„° ìŠ¤í‚¤ë§ˆ (ì„ íƒ) |

**`EvalResults` ì†ì„±:**

| ì†ì„±                      | íƒ€ì…    | ì„¤ëª…                          |
| ------------------------- | ------- | ----------------------------- |
| `.exact_match`            | `float` | BFCL ASTAcc (0~1)             |
| `.relevance_detection_f1` | `float` | BFCL IrrelAcc F1 (0~1)        |
| `.tool_selection`         | `float` | Unitxt Tool Choice (0~1)      |
| `.param_name_recall`      | `float` | Unitxt í•„ìˆ˜ ì¸ì ì»¤ë²„ìœ¨ (0~1) |
| `.param_name_precision`   | `float` | Unitxt ë¶ˆí•„ìš” ì¸ì ë¹„ìœ¨ (0~1) |
| `.params_value_accuracy`  | `float` | Unitxt ê°’ ì •í™•ë„ (0~1)        |
| `.schema_valid_rate`      | `float` | ìŠ¤í‚¤ë§ˆ ì¤€ìˆ˜ìœ¨ (0~1, -1=N/A)   |
| `.to_dict()`              | `dict`  | ë”•ì…”ë„ˆë¦¬ ë³€í™˜                 |
| `.summary()`              | `str`   | ì‚¬ëŒì´ ì½ê¸° ì¢‹ì€ ìš”ì•½         |

### `evaluate_multi_turn(conv_labels, conv_preds, tool_schemas=None) â†’ MultiTurnResults`

| íŒŒë¼ë¯¸í„°                   | íƒ€ì…                      | ì„¤ëª…                          |
| -------------------------- | ------------------------- | ----------------------------- |
| `conversation_labels`      | `list[list[str]]`         | ëŒ€í™”ë³„ ì •ë‹µ í„´ ë¦¬ìŠ¤íŠ¸         |
| `conversation_predictions` | `list[list[str]]`         | ëŒ€í™”ë³„ ì˜ˆì¸¡ í„´ ë¦¬ìŠ¤íŠ¸         |
| `tool_schemas`             | `dict[str, dict] \| None` | í•¨ìˆ˜ë³„ íŒŒë¼ë¯¸í„° ìŠ¤í‚¤ë§ˆ (ì„ íƒ) |

**`MultiTurnResults` ì†ì„±:**

| ì†ì„±                         | íƒ€ì…                | ì„¤ëª…                            |
| ---------------------------- | ------------------- | ------------------------------- |
| `.turn_level_accuracy`       | `float`             | í„´ë³„ ì •í™•ë„ í‰ê·                 |
| `.conversation_success_rate` | `float`             | ëŒ€í™” ì „ì²´ ì„±ê³µë¥                 |
| `.first_failure_turn_avg`    | `float`             | ì²« ì‹¤íŒ¨ í„´ í‰ê·  ìœ„ì¹˜            |
| `.error_cascade_rate`        | `float`             | ì˜¤ë¥˜ ì—°ì‡„ìœ¨                     |
| `.aggregated`                | `EvalResults`       | ì „ì²´ í„´ í•©ì‚° BFCL+Unitxt ë©”íŠ¸ë¦­ |
| `.per_turn_results`          | `list[EvalResults]` | í„´ë³„ ìƒì„¸ ê²°ê³¼                  |
| `.to_dict()`                 | `dict`              | ë”•ì…”ë„ˆë¦¬ ë³€í™˜                   |
| `.summary()`                 | `str`               | ì‚¬ëŒì´ ì½ê¸° ì¢‹ì€ ìš”ì•½           |

### `prepare_eval_data(dataset, test_ratio) â†’ (prompts, labels)`

HuggingFace Datasetì„ í‰ê°€ìš© (í”„ë¡¬í”„íŠ¸, ì •ë‹µ) ìŒìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

```python
from datasets import load_dataset
from evaluations.preprocessing import prepare_eval_data

dataset = load_dataset("iamjoon/ecommerce-function-calling-datasets-korean", split="train")
prompts, labels = prepare_eval_data(dataset, test_ratio=0.2)
```

---

## âš™ï¸ runner.py CLI ì˜µì…˜

```bash
python -m evaluations.runner --help
```

| ì˜µì…˜            | ê¸°ë³¸ê°’                     | ì„¤ëª…                                 |
| --------------- | -------------------------- | ------------------------------------ |
| `--model`       | (í•„ìˆ˜)                     | HuggingFace ëª¨ë¸ ê²½ë¡œ                |
| `--dataset`     | `jjun123/delivery-app-...` | HuggingFace ë°ì´í„°ì…‹ ê²½ë¡œ            |
| `--test-ratio`  | `0.2`                      | í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¹„ìœ¨                   |
| `--output`      | `evaluation_results.csv`   | ê²°ê³¼ CSV ì €ì¥ ê²½ë¡œ                   |
| `--temperature` | `0`                        | ìƒ˜í”Œë§ ì˜¨ë„ (0 = greedy)             |
| `--max-tokens`  | `2048`                     | ìµœëŒ€ ìƒì„± í† í° ìˆ˜                    |
| `--multi-turn`  | (í”Œë˜ê·¸)                   | ë©€í‹°í„´(HammerBench) í‰ê°€ë„ í•¨ê»˜ ì‹¤í–‰ |

**ê²°ê³¼ë¬¼:**
- `evaluation_results.csv` â€” í”„ë¡¬í”„íŠ¸, ì •ë‹µ, ì˜ˆì¸¡ ìƒì„¸ ê¸°ë¡
- `evaluation_results.metrics.json` â€” ì „ì²´ ë©”íŠ¸ë¦­ JSON (ë©€í‹°í„´ í¬í•¨)

---

## ğŸ§ª í…ŒìŠ¤íŠ¸

```bash
python -m pytest tests/test_evaluations.py -v
```

35ê°œ í…ŒìŠ¤íŠ¸: íŒŒì‹±, BFCL ë©”íŠ¸ë¦­, Unitxt ë¶„í•´(Recall/Precision ë¶„ë¦¬, ìŠ¤í‚¤ë§ˆ ê²€ì¦), HammerBench ë©€í‹°í„´(ëŒ€í™” ì„±ê³µë¥ , ì˜¤ë¥˜ ì—°ì‡„ìœ¨), ì „ì²˜ë¦¬(ìŠ¤í‚¤ë§ˆ ì¶”ì¶œ) ë“±ì„ ê²€ì¦í•©ë‹ˆë‹¤.
