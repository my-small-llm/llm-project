# 골드 평가용 테스트셋 구축 전략: 함수별 vs 상황별(카테고리) 구성

AI 에이전트(배달 앱 챗봇)의 성능을 다운스트림 레벨에서 정밀하게 평가하기 위한 '골드(Gold) 데이터셋'을 구축할 때, 기준을 **어떻게 나눌 것인가(함수 중심 vs 상황 중심)**는 모델이 실제 서비스 환경에서 얼마나 유용할지를 결정하는 핵심 요소가 됩니다.

이 문서에서는 평가 데이터셋을 함수별로 구성하는 방식이 왜 한계가 많으며, 제안된 8개의 상황별 카테고리 구성이 왜 더 이상적인지에 대해 정리합니다.

---

## 🚫 1. 왜 함수별로 평가 데이터를 구성하는 것이 좋지 않은가?

함수 중심의 평가 세트(`search_restaurants`, `add_to_cart` 등을 각각 개별적으로 평가하는 방식)는 모델이 **API 1~2개를 고정적으로 호출하는 "기계적인 동작"을 점검하는 데는 좋으나, "에이전트로서의 대화 및 추론 능력"을 반영하지 못합니다.**

구체적인 한계는 다음과 같습니다.

### 1) "현실 고객"은 함수 단위로 대화하지 않는다
*   실제 고객은 "내 장바구니를 조회해줘(`get_cart`), 그리고 그 장바구니에 치킨을 담아줘(`add_to_cart`)"라고 기계적으로 말하지 않습니다. 
*   대신, "장바구니에 치킨 1마리 추가해줘, 아까 담은 피자랑 같이"라는 아주 복합적인 의도의 문장을 던집니다. 즉, **한 번의 사용자 발화에서 여러 번(Multi-call) 함수를 순차적으로 혹은 병렬로 호출**해야 하는 상황을 평가하기 어렵습니다.

### 2) 맥락 유지와 의도 전환(Context & Intent Shift) 평가의 부재
*   **배달 주문은 본질적으로 연쇄적인 멀티턴 흐름입니다** (검색 $\rightarrow$ 담기 $\rightarrow$ 결제 확인 $\rightarrow$ 주문 확정).
*   함수별로 평가를 나누면 이전 턴에서 가져온 "현재 식당 아이디(`restaurant_id`)"나 "현재 고객 주소" 같은 **컨텍스트를 모델이 얼마나 끈질기게 붙들고 있는지**를 테스트할 수 없습니다.

### 3) 함수를 호출하면 안 되는 '거절' 능력을 평가하기 어려움
*   "이거 배달비 깎아줘", "여기 최악이야 환불해줘" 같은 발화는 어떤 함수에도 속하지 않으며, `IrrelAcc`(비관련성 탐지)를 평가하는 중요한 문항입니다. 함수별로 할당된 벤치마크에서는 이런 시나리오가 아예 들어설 자리가 없습니다.

---

## ✅ 2. 8개 카테고리(상황별) 구성이 압도적으로 좋은 이유

제안된 8개의 카테고리(단순검색, 메뉴, 장바구니, 주문, 주문이력, 멀티턴 복합, 비지원 시나리오, 엣지케이스)로 골드 데이터셋을 구축하면, 위에서 지적된 맹점들을 완벽히 보완할 수 있습니다.

### 1) 모델의 약점을 "진단(Diagnosis)"할 수 있습니다
*   함수 호출률이 90%로 높더라도, 엣지 케이스 점수가 낮다면 "오타나 맥락 변화에 아주 취약함"을 찾아낼 수 있습니다.
*   "장바구니"는 잘 되는데 "멀티턴 복합"에서 점수가 떨어진다면 "모델의 단기 기억력(컨텍스트 유지)에 심각한 하자가 있음"을 알 수 있습니다.
*   *이렇듯, 특정 상황에서 터지는 버그를 찾아내기 위한 **Unitxt**나 **HammerBench**의 평가 관점과 매우 잘 맞아떨어집니다.*

### 2) 서비스 오픈 전 필수 통과해야 할 '허들(Hurdle)' 역할
*   상황별 세트는 모델이 **실제 배달 앱 상담사라면 반드시 겪게 될 라이프사이클 전체**를 반영합니다.
*   단순히 API 호출이 문법에 맞는지가 아니라, **[검색 $\rightarrow$ 메뉴 조회 $\rightarrow$ 옵션 변경 $\rightarrow$ 주문]** 이라는 도메인 유즈케이스 시나리오 도달률 자체를 측정할 수 있게 해줍니다. 골드 테스트는 결국 "이게 배포 가능한 모델인가?"를 결정하는 정성적/정량적 기준이 되기 때문입니다.

### 3) 도메인 갭(TSTR) 측정의 기준점
*   결국 파인튜닝된 모델이 (Train on Synthetic, Test on Real)의 실제 고객 환경에서 얼마나 잘 작동하는지 파악하려면, 테스트 셋이 최대한 **진짜 실제 사용자의 대화 비중과 비슷하게 쪼개져 있어야 합니다.**
*   현업에서 자주 발생하는 8가지 케이스를 비율별로 통제해둔다는 것은, 가장 현실적인 '미니 배달 서비스'를 시뮬레이션 해놓은 것과 동일합니다.
